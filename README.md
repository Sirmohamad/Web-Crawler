# Web-Crawler
A general-purpose smart web crawler that recursively extracts website content using BFS, preserves full URL-based directory structure, and saves files locally. Supports PDF/Word/Excel/PowerPoint extraction, customizable crawl depth, domain restriction, CSS-based content targeting, and duplicate prevention using hashing.
